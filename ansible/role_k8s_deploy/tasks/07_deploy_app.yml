---
- name: Deploy web page(run in master)
  block:
  - name: Add Taints to worker01(Prometheus and Grafana run on worker01)
    shell: kubectl taint nodes worker01 run=promgraf:NoSchedule

  - name: Create secret for Amazon Elastic Block Store (EBS) CSI driver
    shell: |
      kubectl delete secret aws-secret --namespace kube-system
      key=$(sed -r '2!d;s/.*=//' .aws/credentials)
      access_key=$(sed -r '3!d;s/.*=//' .aws/credentials)
      kubectl create secret generic aws-secret \
        --namespace kube-system \
        --from-literal "key_id=${key}" \
        --from-literal "access_key=${access_key}"
    #sed - take 2 and 3 line and delete everything before "=" including "="
    #need .aws/credentials(02_init_master.yml)

  - name: Install Amazon Elastic Block Store (EBS) CSI driver
    shell: kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-1.24"

  - name: Copy files to master from localhost to deploy Prometheus and alertmanager
    copy:
      src: helm
      dest: $HOME

  - name: Change app-password in cm-alert.yaml for email and token for Telegram
    shell: |
      sed -i "s/app-password/$(sed '1!d' \.alert\/secret-key.txt)/" helm/alertmanager/templates/cm-alert.yaml
      sed -i "s/token-telegram/$(sed '2!d' \.alert\/secret-key.txt)/" helm/alertmanager/templates/cm-alert.yaml
    #need .alert/secret-key.txt(02_init_master.yml)

  #- name: Generate values.yaml
  #  template: 
  #    src: values.j2
  #    dest: $HOME/helm_chart/values.yaml

  - name: Run Prometheus and exporters
    shell: |
      cd helm/prometheus/
      while ! helm upgrade --install -n monitoring --create-namespace prometheus .; do sleep 5; done
      helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
      helm repo update
      helm upgrade --install -n monitoring kube-state-metrics prometheus-community/kube-state-metrics
#      kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

  - name: Run Alertmanager
    shell: |
      cd helm/alertmanager/
      helm upgrade --install -n monitoring alertmanager .

  - name: Run Blackbox
    shell: |
      cd helm/blackbox/
      helm upgrade --install -n monitoring blackbox .

  - name: Run Grafana
    shell: |
      cd helm/grafana/
      helm upgrade --install -n monitoring --create-namespace grafana .

  - name: Set DeleteOnTermination in "true" on volume created of Prometheus to be one will delete when we run command terraform destroy
    #if this command doesn't run you need to delete the volume in AWS manually
    shell: |
      while ! aws ec2 modify-instance-attribute --instance-id \
        $(aws ec2 describe-volumes --filters Name=tag:pv,Values=prometheus --query 'Volumes[0].Attachments[0].InstanceId' --output text --region {{ region_from_terraform }}) \
        --block-device-mappings "[{\"DeviceName\": \
        \"$(aws ec2 describe-volumes --filters Name=tag:pv,Values=prometheus --query 'Volumes[0].Attachments[0].Device' --output text --region {{ region_from_terraform }})\",\
        \"Ebs\":{\"DeleteOnTermination\":true}}]" --region {{ region_from_terraform }}; do sleep 5; done
    #id=$(aws ec2 describe-volumes --filters Name=tag:pv,Values=prometheus --query 'Volumes[0].Attachments[0].InstanceId' --output text --region eu-north-1)
    #device=$(aws ec2 describe-volumes --filters Name=tag:pv,Values=prometheus --query 'Volumes[0].Attachments[0].Device' --output text --region eu-north-1)
    #aws ec2 modify-instance-attribute --instance-id $id --block-device-mappings "[{\"DeviceName\": \"$device\",\"Ebs\":{\"DeleteOnTermination\":true}}]" --region eu-north-1
    #aws ec2 describe-volumes --filters Name=tag:pv,Values=prometheus --region eu-north-1

  - name: Approve CSRs(to see 04_cert_kudeadm.yml)
    shell: for csr_name in $(kubectl get csr | grep -i pending | awk '{print $1}'); do kubectl certificate approve $csr_name; done
  become: false
  #if run with become: true(in ansible.cfg) then %HOME will be /root and all run will be as root  
  when: "'ansible_master' in group_names" 

- name: Run in workers
  block:
  - name: Reload configuration of Prometheus(if you've run terraform already and not run destroy before)
    shell: for (( i=1; i<=5; i++)); do curl -X POST localhost:9090/-/reload; if [ $? == 0 ]; then break; fi; sleep 10; done
    args:
      executable: /usr/bin/bash
    ignore_errors: true

  - name: Reload configuration of Alertmanager(if you've run terraform already and not run destroy before)
    shell: for (( i=1; i<=5; i++)); do pgrep alertmanager | sudo xargs kill -HUP; if [ $? == 0 ]; then break; fi; sleep 10; done
    args:
      executable: /usr/bin/bash    
    ignore_errors: true

  - name: Reload configuration of Blackbox(if you've run terraform already and not run destroy before)
    shell: for (( i=1; i<=5; i++)); do pgrep blackbox | sudo xargs kill -HUP; if [ $? == 0 ]; then break; fi; sleep 10; done
    args:
      executable: /usr/bin/bash    
    #do 5 time with delay 10 seconds - wait to pod deploy
    #if [ $? == 0 ] - if command didn't work successfully and pass 50 seconds this worker doesn't have this pod
    #executable: /usr/bin/bash - default - /bin/sh - "for (( ))" doesn't work
    ignore_errors: true   
  when: "'ansible_workers' in group_names"